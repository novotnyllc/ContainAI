name: Build and Publish Images

on:
  push:
    branches:
      - main
    paths:
      - 'docker/**'
      - 'host/**'
      - 'agent-configs/**'
      - 'scripts/**'
      - 'config.toml'
      - '.github/workflows/build-runtime-images.yml'
  pull_request:
    branches:
      - main
    paths:
      - 'docker/**'
      - 'host/**'
      - 'agent-configs/**'
      - 'scripts/**'
      - 'config.toml'
      - '.github/workflows/build-runtime-images.yml'
  schedule:
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      channel:
        description: 'Channel to publish (dev, nightly, prod)'
        required: false
        default: dev
        type: choice
        options:
          - dev
          - nightly
          - prod
      version:
        description: 'Optional version tag (defaults to channel for dev/nightly or git tag for prod)'
        required: false
        type: string

env:
  REGISTRY: ghcr.io
  IMAGE_NAMESPACE: ${{ github.repository_owner }}
  TRIVY_VERSION: v0.53.0
  ARTIFACTS_ROOT: artifacts
  ARTIFACTS_PUBLISH: artifacts/publish

jobs:
  determine-context:
    name: Determine channel/tags
    runs-on: ubuntu-latest
    outputs:
      channel: ${{ steps.channel.outputs.channel }}
      version: ${{ steps.channel.outputs.version }}
      immutable_tag: ${{ steps.channel.outputs.immutable_tag }}
      moving_tags: ${{ steps.channel.outputs.moving_tags }}
      push: ${{ steps.channel.outputs.push }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - id: channel
        env:
          DISPATCH_CHANNEL: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.channel || '' }}
          DISPATCH_VERSION: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.version || '' }}
          GH_EVENT_NAME: ${{ github.event_name }}
          REF_NAME: ${{ github.ref_name }}
        run: |
          scripts/ci/determine-channel.sh \
            --event-name "$GH_EVENT_NAME" \
            --ref-name "$REF_NAME" \
            --dispatch-channel "$DISPATCH_CHANNEL" \
            --dispatch-version "$DISPATCH_VERSION"

  # Scan build context for secrets BEFORE any images are built
  # This catches secrets at the source and prevents them from being pushed to the registry
  scan-build-context:
    name: Scan build context for secrets
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Trivy CLI
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
            | sudo sh -s -- -b /usr/local/bin ${{ env.TRIVY_VERSION }}

      - name: Scan build context for secrets
        run: |
          echo "ðŸ” Scanning build context for secrets before image builds..."
          # Scan directories that get COPYed into images
          for dir in docker agent-configs host scripts; do
            if [[ -d "$dir" ]]; then
              echo "  Scanning $dir..."
              trivy fs --scanners secret --severity HIGH,CRITICAL --exit-code 1 --no-progress "$dir"
            fi
          done
          echo "âœ“ Build context secret scan passed"

  build-base-arch:
    name: Build base image (${{ matrix.arch_slug }})
    needs: [determine-context, scan-build-context]
    if: ${{ needs.determine-context.outputs.push == 'true' || github.event_name == 'pull_request' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
      attestations: write
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(github.event_name == 'pull_request' && '[{"arch":"linux/amd64","arch_slug":"amd64","cache_scope":"containai-base-amd64"}]' || '[{"arch":"linux/amd64","arch_slug":"amd64","cache_scope":"containai-base-amd64"},{"arch":"linux/arm64","arch_slug":"arm64","cache_scope":"containai-base-arm64"}]') }}
    env:
      IMAGE_NAME: containai-base
    steps:
      - name: Free up disk space
        run: |
          # Remove large preinstalled packages we don't need
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL
          sudo docker image prune -af
          df -h /

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver: ${{ github.event_name == 'pull_request' && 'docker' || 'docker-container' }}

      - name: Log in to Container Registry
        if: needs.determine-context.outputs.push == 'true'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Compose tags
        id: taglist
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ env.IMAGE_NAME }}"
          arch_tag="${repo}:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
          printf "tag=%s\n" "$arch_tag" >> "$GITHUB_OUTPUT"

      - name: Build and push base image (${{ matrix.arch_slug }})
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/base/Dockerfile
          push: ${{ needs.determine-context.outputs.push == 'true' }}
          load: ${{ github.event_name == 'pull_request' }}
          tags: ${{ steps.taglist.outputs.tag }}
          cache-from: type=gha,scope=${{ matrix.cache_scope }}
          cache-to: type=gha,scope=${{ matrix.cache_scope }},mode=max,compression=zstd
          platforms: ${{ matrix.arch }}

      - name: Save base image tar (PR)
        if: github.event_name == 'pull_request'
        run: |
          mkdir -p image-tars
          docker save "${{ steps.taglist.outputs.tag }}" | gzip > "image-tars/containai-base-${{ matrix.arch_slug }}.tar.gz"
        shell: bash

      - name: Upload base image tar (PR)
        if: github.event_name == 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: base-tar-${{ matrix.arch_slug }}
          path: image-tars/containai-base-${{ matrix.arch_slug }}.tar.gz
          if-no-files-found: error

      - name: Generate artifact attestation
        if: needs.determine-context.outputs.push == 'true'
        uses: actions/attest-build-provenance@v1
        with:
          subject-name: ${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ env.IMAGE_NAME }}
          subject-digest: ${{ steps.build.outputs.digest }}
          push-to-registry: true

      - name: Upload arch digest artifact
        if: needs.determine-context.outputs.push == 'true'
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ env.IMAGE_NAME }}"
          mkdir -p "${{ env.ARTIFACTS_ROOT }}/digests"
          printf '{"image":"%s","repository":"%s","arch":"%s","tag":"%s","digest":"%s","ref":"%s@%s"}\n' \
            "${{ env.IMAGE_NAME }}" "$repo" "${{ matrix.arch }}" "${{ steps.taglist.outputs.tag }}" "${{ steps.build.outputs.digest }}" "$repo" "${{ steps.build.outputs.digest }}" \
            > "${{ env.ARTIFACTS_ROOT }}/digests/${{ env.IMAGE_NAME }}-${{ matrix.arch_slug }}.json"
        shell: bash

      - name: Publish arch digest artifact
        if: needs.determine-context.outputs.push == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: arch-digest-${{ env.IMAGE_NAME }}-${{ matrix.arch_slug }}
          path: ${{ env.ARTIFACTS_ROOT }}/digests/${{ env.IMAGE_NAME }}-${{ matrix.arch_slug }}.json
          if-no-files-found: error

  assemble-base-manifest:
    name: Assemble base manifest
    needs:
      - determine-context
      - build-base-arch
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Download arch digests
        uses: actions/download-artifact@v4
        with:
          path: arch-digests/base
          pattern: arch-digest-containai-base-*
          merge-multiple: true

      - name: Create manifest
        id: manifest
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-base"
          mapfile -t tags < <(jq -r '.tag' arch-digests/base/*.json | sed '/^$/d')
          if [ "${#tags[@]}" -eq 0 ]; then
            echo "No arch tags found for manifest assembly" >&2
            exit 1
          fi
          docker buildx imagetools create --tag "${repo}:${{ needs.determine-context.outputs.immutable_tag }}" "${tags[@]}"
          digest=$(docker buildx imagetools inspect "${repo}:${{ needs.determine-context.outputs.immutable_tag }}" | awk '/Digest:/ {print $2; exit}')
          echo "digest=$digest" >> "$GITHUB_OUTPUT"
          mkdir -p "${{ env.ARTIFACTS_ROOT }}/digests"
          printf '{"image":"%s","repository":"%s","digest":"%s"}\n' "containai-base" "$repo" "$digest" > "${{ env.ARTIFACTS_ROOT }}/digests/containai-base.json"

      - name: Publish manifest digest artifact
        uses: actions/upload-artifact@v4
        with:
          name: manifest-digest-containai-base
          path: ${{ env.ARTIFACTS_ROOT }}/digests/containai-base.json
          if-no-files-found: error

  build-containai-arch:
    name: Build containai image (${{ matrix.arch_slug }})
    needs:
      - determine-context
      - build-base-arch
    if: ${{ needs.determine-context.outputs.push == 'true' || github.event_name == 'pull_request' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
      attestations: write
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(github.event_name == 'pull_request' && '[{"arch":"linux/amd64","arch_slug":"amd64","cache_scope":"runtime-containai-amd64"}]' || '[{"arch":"linux/amd64","arch_slug":"amd64","cache_scope":"runtime-containai-amd64"},{"arch":"linux/arm64","arch_slug":"arm64","cache_scope":"runtime-containai-arm64"}]') }}
    env:
      IMAGE_NAME: containai
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download base image tar (PR)
        if: github.event_name == 'pull_request'
        uses: actions/download-artifact@v4
        with:
          name: base-tar-${{ matrix.arch_slug }}
          path: image-tars/base

      - name: Load base image (PR)
        if: github.event_name == 'pull_request'
        run: |
          gunzip -c image-tars/base/containai-base-${{ matrix.arch_slug }}.tar.gz | docker load
        shell: bash

      - name: Retag base image for local use (PR)
        if: github.event_name == 'pull_request'
        run: |
          docker tag "${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-base:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}" \
            "containai-base:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
        shell: bash

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver: ${{ github.event_name == 'pull_request' && 'docker' || 'docker-container' }}

      - name: Log in to Container Registry
        if: needs.determine-context.outputs.push == 'true'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Select base image reference
        id: base_image
        run: |
          if [ "${{ needs.determine-context.outputs.push }}" = "true" ]; then
            base_ref="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-base:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
          else
            base_ref="containai-base:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
          fi
          echo "tag=$base_ref" >> "$GITHUB_OUTPUT"
        shell: bash

      - name: Compose tags
        id: taglist
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ env.IMAGE_NAME }}"
          arch_tag="${repo}:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
          printf "tag=%s\n" "$arch_tag" >> "$GITHUB_OUTPUT"

      - name: Build and push image (single-arch)
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/agents/all/Dockerfile
          push: ${{ needs.determine-context.outputs.push == 'true' }}
          load: ${{ github.event_name == 'pull_request' }}
          tags: ${{ steps.taglist.outputs.tag }}
          build-args: |
            BASE_IMAGE=${{ steps.base_image.outputs.tag }}
          cache-from: type=gha,scope=${{ matrix.cache_scope }}
          cache-to: type=gha,scope=${{ matrix.cache_scope }},mode=max,compression=zstd
          platforms: ${{ matrix.arch }}

      - name: Save containai image tar (PR)
        if: github.event_name == 'pull_request'
        run: |
          mkdir -p image-tars
          docker save "${{ steps.taglist.outputs.tag }}" | gzip > "image-tars/containai-${{ matrix.arch_slug }}.tar.gz"
        shell: bash

      - name: Upload containai image tar (PR)
        if: github.event_name == 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: containai-tar-${{ matrix.arch_slug }}
          path: image-tars/containai-${{ matrix.arch_slug }}.tar.gz
          if-no-files-found: error

      - name: Generate artifact attestation
        if: needs.determine-context.outputs.push == 'true'
        uses: actions/attest-build-provenance@v1
        with:
          subject-name: ${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ env.IMAGE_NAME }}
          subject-digest: ${{ steps.build.outputs.digest }}
          push-to-registry: true

      - name: Upload arch digest artifact
        if: needs.determine-context.outputs.push == 'true'
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ env.IMAGE_NAME }}"
          mkdir -p "${{ env.ARTIFACTS_ROOT }}/digests"
          printf '{"image":"%s","repository":"%s","arch":"%s","tag":"%s","digest":"%s","ref":"%s@%s"}\n' \
            "${{ env.IMAGE_NAME }}" "$repo" "${{ matrix.arch }}" "${{ steps.taglist.outputs.tag }}" "${{ steps.build.outputs.digest }}" "$repo" "${{ steps.build.outputs.digest }}" \
            > "${{ env.ARTIFACTS_ROOT }}/digests/${{ env.IMAGE_NAME }}-${{ matrix.arch_slug }}.json"
        shell: bash

      - name: Publish arch digest artifact
        if: needs.determine-context.outputs.push == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: arch-digest-${{ env.IMAGE_NAME }}-${{ matrix.arch_slug }}
          path: ${{ env.ARTIFACTS_ROOT }}/digests/${{ env.IMAGE_NAME }}-${{ matrix.arch_slug }}.json
          if-no-files-found: error

  assemble-containai-manifest:
    name: Assemble containai manifest
    needs:
      - determine-context
      - build-containai-arch
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Download arch digests
        uses: actions/download-artifact@v4
        with:
          path: arch-digests/containai
          pattern: arch-digest-containai-*
          merge-multiple: true

      - name: Create manifest
        id: manifest
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai"
          mapfile -t tags < <(jq -r 'select(.image=="containai") | .tag' arch-digests/containai/*.json | sed '/^$/d')
          if [ "${#tags[@]}" -eq 0 ]; then
            echo "No arch tags found for manifest assembly" >&2
            exit 1
          fi
          docker buildx imagetools create --tag "${repo}:${{ needs.determine-context.outputs.immutable_tag }}" "${tags[@]}"
          digest=$(docker buildx imagetools inspect "${repo}:${{ needs.determine-context.outputs.immutable_tag }}" | awk '/Digest:/ {print $2; exit}')
          echo "digest=$digest" >> "$GITHUB_OUTPUT"
          mkdir -p "${{ env.ARTIFACTS_ROOT }}/digests"
          printf '{"image":"%s","repository":"%s","digest":"%s"}\n' "containai" "$repo" "$digest" > "${{ env.ARTIFACTS_ROOT }}/digests/containai.json"

      - name: Publish manifest digest artifact
        uses: actions/upload-artifact@v4
        with:
          name: manifest-digest-containai
          path: ${{ env.ARTIFACTS_ROOT }}/digests/containai.json
          if-no-files-found: error

  build-variants-arch:
    name: Build variant image (${{ matrix.image }} / ${{ matrix.arch_slug }})
    needs:
      - determine-context
      - build-containai-arch
    if: ${{ needs.determine-context.outputs.push == 'true' || github.event_name == 'pull_request' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
      attestations: write
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(github.event_name == 'pull_request' && '[{"image":"containai-copilot","dockerfile":"docker/agents/copilot/Dockerfile","cache":"runtime-copilot","base_from_containai":true,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-codex","dockerfile":"docker/agents/codex/Dockerfile","cache":"runtime-codex","base_from_containai":true,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-claude","dockerfile":"docker/agents/claude/Dockerfile","cache":"runtime-claude","base_from_containai":true,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-proxy","dockerfile":"docker/proxy/Dockerfile","cache":"runtime-proxy","base_from_containai":false,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-log-forwarder","dockerfile":"docker/log-forwarder/Dockerfile","cache":"runtime-log-forwarder","base_from_containai":false,"arch":"linux/amd64","arch_slug":"amd64"}]' || '[{"image":"containai-copilot","dockerfile":"docker/agents/copilot/Dockerfile","cache":"runtime-copilot","base_from_containai":true,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-copilot","dockerfile":"docker/agents/copilot/Dockerfile","cache":"runtime-copilot","base_from_containai":true,"arch":"linux/arm64","arch_slug":"arm64"},{"image":"containai-codex","dockerfile":"docker/agents/codex/Dockerfile","cache":"runtime-codex","base_from_containai":true,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-codex","dockerfile":"docker/agents/codex/Dockerfile","cache":"runtime-codex","base_from_containai":true,"arch":"linux/arm64","arch_slug":"arm64"},{"image":"containai-claude","dockerfile":"docker/agents/claude/Dockerfile","cache":"runtime-claude","base_from_containai":true,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-claude","dockerfile":"docker/agents/claude/Dockerfile","cache":"runtime-claude","base_from_containai":true,"arch":"linux/arm64","arch_slug":"arm64"},{"image":"containai-proxy","dockerfile":"docker/proxy/Dockerfile","cache":"runtime-proxy","base_from_containai":false,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-proxy","dockerfile":"docker/proxy/Dockerfile","cache":"runtime-proxy","base_from_containai":false,"arch":"linux/arm64","arch_slug":"arm64"},{"image":"containai-log-forwarder","dockerfile":"docker/log-forwarder/Dockerfile","cache":"runtime-log-forwarder","base_from_containai":false,"arch":"linux/amd64","arch_slug":"amd64"},{"image":"containai-log-forwarder","dockerfile":"docker/log-forwarder/Dockerfile","cache":"runtime-log-forwarder","base_from_containai":false,"arch":"linux/arm64","arch_slug":"arm64"}]') }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download containai image tar (PR, when needed)
        if: github.event_name == 'pull_request' && matrix.base_from_containai
        uses: actions/download-artifact@v4
        with:
          name: containai-tar-${{ matrix.arch_slug }}
          path: image-tars/containai

      - name: Load containai image (PR, when needed)
        if: github.event_name == 'pull_request' && matrix.base_from_containai
        run: |
          gunzip -c image-tars/containai/containai-${{ matrix.arch_slug }}.tar.gz | docker load
        shell: bash

      - name: Retag containai image for local use (PR, when needed)
        if: github.event_name == 'pull_request' && matrix.base_from_containai
        run: |
          docker tag "${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}" \
            "containai:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
        shell: bash

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver: ${{ github.event_name == 'pull_request' && 'docker' || 'docker-container' }}

      - name: Log in to Container Registry
        if: needs.determine-context.outputs.push == 'true'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Select base image reference
        if: matrix.base_from_containai
        id: base_image
        run: |
          if [ "${{ needs.determine-context.outputs.push }}" = "true" ]; then
            base_ref="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
          else
            base_ref="containai:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
          fi
          echo "tag=$base_ref" >> "$GITHUB_OUTPUT"
        shell: bash

      - name: Compose tags
        id: taglist
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ matrix.image }}"
          arch_tag="${repo}:${{ needs.determine-context.outputs.immutable_tag }}-${{ matrix.arch_slug }}"
          printf "tag=%s\n" "$arch_tag" >> "$GITHUB_OUTPUT"

      - name: Build and push image (single-arch)
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ${{ matrix.dockerfile }}
          push: ${{ needs.determine-context.outputs.push == 'true' }}
          load: ${{ github.event_name == 'pull_request' }}
          tags: ${{ steps.taglist.outputs.tag }}
          build-args: ${{ matrix.base_from_containai && format('BASE_IMAGE={0}', steps.base_image.outputs.tag) || '' }}
          cache-from: type=gha,scope=${{ matrix.cache }}-${{ matrix.arch_slug }}
          cache-to: type=gha,scope=${{ matrix.cache }}-${{ matrix.arch_slug }},mode=max,compression=zstd
          platforms: ${{ matrix.arch }}

      - name: Save variant image tar (PR)
        if: github.event_name == 'pull_request'
        run: |
          mkdir -p image-tars
          docker save "${{ steps.taglist.outputs.tag }}" | gzip > "image-tars/${{ matrix.image }}-${{ matrix.arch_slug }}.tar.gz"
        shell: bash

      - name: Upload variant image tar (PR)
        if: github.event_name == 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: variant-tar-${{ matrix.image }}-${{ matrix.arch_slug }}
          path: image-tars/${{ matrix.image }}-${{ matrix.arch_slug }}.tar.gz
          if-no-files-found: error

      - name: Generate artifact attestation
        if: needs.determine-context.outputs.push == 'true'
        uses: actions/attest-build-provenance@v1
        with:
          subject-name: ${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ matrix.image }}
          subject-digest: ${{ steps.build.outputs.digest }}
          push-to-registry: true

      - name: Upload arch digest artifact
        if: needs.determine-context.outputs.push == 'true'
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ matrix.image }}"
          mkdir -p "${{ env.ARTIFACTS_ROOT }}/digests"
          printf '{"image":"%s","repository":"%s","arch":"%s","tag":"%s","digest":"%s","ref":"%s@%s"}\n' \
            "${{ matrix.image }}" "$repo" "${{ matrix.arch }}" "${{ steps.taglist.outputs.tag }}" "${{ steps.build.outputs.digest }}" "$repo" "${{ steps.build.outputs.digest }}" \
            > "${{ env.ARTIFACTS_ROOT }}/digests/${{ matrix.image }}-${{ matrix.arch_slug }}.json"
        shell: bash

      - name: Publish arch digest artifact
        if: needs.determine-context.outputs.push == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: arch-digest-${{ matrix.image }}-${{ matrix.arch_slug }}
          path: ${{ env.ARTIFACTS_ROOT }}/digests/${{ matrix.image }}-${{ matrix.arch_slug }}.json
          if-no-files-found: error

  assemble-variant-manifest:
    name: Assemble variant manifests (${{ matrix.image }})
    needs:
      - determine-context
      - build-variants-arch
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    strategy:
      fail-fast: false
      matrix:
        image:
          - containai-copilot
          - containai-codex
          - containai-claude
          - containai-proxy
          - containai-log-forwarder
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Download arch digests
        uses: actions/download-artifact@v4
        with:
          path: arch-digests/${{ matrix.image }}
          pattern: arch-digest-${{ matrix.image }}-*
          merge-multiple: true

      - name: Create manifest
        id: manifest
        run: |
          repo="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/${{ matrix.image }}"
          mapfile -t tags < <(jq -r '.tag' arch-digests/${{ matrix.image }}/*.json | sed '/^$/d')
          if [ "${#tags[@]}" -eq 0 ]; then
            echo "No arch tags found for manifest assembly" >&2
            exit 1
          fi
          docker buildx imagetools create --tag "${repo}:${{ needs.determine-context.outputs.immutable_tag }}" "${tags[@]}"
          digest=$(docker buildx imagetools inspect "${repo}:${{ needs.determine-context.outputs.immutable_tag }}" | awk '/Digest:/ {print $2; exit}')
          echo "digest=$digest" >> "$GITHUB_OUTPUT"
          mkdir -p "${{ env.ARTIFACTS_ROOT }}/digests"
          printf '{"image":"%s","repository":"%s","digest":"%s"}\n' "${{ matrix.image }}" "$repo" "$digest" > "${{ env.ARTIFACTS_ROOT }}/digests/${{ matrix.image }}.json"

      - name: Publish manifest digest artifact
        uses: actions/upload-artifact@v4
        with:
          name: manifest-digest-${{ matrix.image }}
          path: ${{ env.ARTIFACTS_ROOT }}/digests/${{ matrix.image }}.json
          if-no-files-found: error

  finalize-tags:
    name: Finalize tags and collect digests
    needs:
      - determine-context
      - assemble-base-manifest
      - assemble-containai-manifest
      - assemble-variant-manifest
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      images: ${{ steps.combine.outputs.images }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Download manifest digests
        uses: actions/download-artifact@v4
        with:
          path: digests
          pattern: manifest-digest-*
          merge-multiple: true

      - name: Combine digests
        id: combine
        run: |
          mapfile -t files < <(find digests -name "*.json" -type f)
          if [ "${#files[@]}" -eq 0 ]; then
            echo "No manifest digest artifacts found" >&2
            exit 1
          fi
          jq -s 'map(.)' "${files[@]}" > digests/all.json
          echo "images=$(jq -c . digests/all.json)" >> "$GITHUB_OUTPUT"
        shell: bash

      - name: Apply moving tags
        run: |
          scripts/ci/apply-moving-tags.sh \
            --digests digests/all.json \
            --immutable-tag "${{ needs.determine-context.outputs.immutable_tag }}" \
            --moving-tags "${{ needs.determine-context.outputs.moving_tags }}"
        shell: bash

  publish-payload:
    name: Package and publish payload artifact
    needs:
      - determine-context
      - finalize-tags
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
      attestations: write
    env:
      VERSION: ${{ needs.determine-context.outputs.version }}
      CHANNEL: ${{ needs.determine-context.outputs.channel }}
    outputs:
      payload_ref: ${{ steps.push.outputs.ref }}
      payload_digest: ${{ steps.push.outputs.digest }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set image digest env
        id: digests
        run: |
          images='${{ needs.finalize-tags.outputs.images }}'
          get_digest() {
            echo "$images" | jq -r --arg name "$1" '.[] | select(.image==$name) | .digest'
          }
          {
            echo "IMAGE_DIGEST=$(get_digest 'containai')"
            echo "IMAGE_DIGEST_COPILOT=$(get_digest 'containai-copilot')"
            echo "IMAGE_DIGEST_CODEX=$(get_digest 'containai-codex')"
            echo "IMAGE_DIGEST_CLAUDE=$(get_digest 'containai-claude')"
            echo "IMAGE_DIGEST_PROXY=$(get_digest 'containai-proxy')"
            echo "IMAGE_DIGEST_LOG_FORWARDER=$(get_digest 'containai-log-forwarder')"
          } >> "$GITHUB_ENV"
        shell: bash

      - name: Generate profile.env
        run: |
          mkdir -p "${{ env.ARTIFACTS_PUBLISH }}"
          scripts/release/write-profile-env.sh \
            --prefix containai \
            --tag "$VERSION" \
            --owner "${{ env.IMAGE_NAMESPACE }}" \
            --out "${{ env.ARTIFACTS_PUBLISH }}/profile.env" \
            --channel "$CHANNEL" \
            --registry "${{ env.REGISTRY }}" \
            --mode env

      - name: Ensure artifacts dir
        run: mkdir -p "${{ env.ARTIFACTS_PUBLISH }}/${VERSION}"

      - name: Build payload (no packaging)
        id: build_payload
        run: |
          output=$(scripts/release/build-payload.sh \
            --version "$VERSION" \
            --out "${{ env.ARTIFACTS_PUBLISH }}" \
            --profile-env "${{ env.ARTIFACTS_PUBLISH }}/profile.env")
          echo "$output"
          # Extract actual version (includes git sha for dev/nightly) and export to env
          payload_version=$(echo "$output" | grep '^PAYLOAD_VERSION=' | cut -d= -f2)
          echo "payload_version=$payload_version" >> "$GITHUB_OUTPUT"
          echo "VERSION=$payload_version" >> "$GITHUB_ENV"
        env:
          IMAGE_DIGEST: ${{ env.IMAGE_DIGEST }}
          IMAGE_DIGEST_COPILOT: ${{ env.IMAGE_DIGEST_COPILOT }}
          IMAGE_DIGEST_CODEX: ${{ env.IMAGE_DIGEST_CODEX }}
          IMAGE_DIGEST_CLAUDE: ${{ env.IMAGE_DIGEST_CLAUDE }}
          IMAGE_DIGEST_PROXY: ${{ env.IMAGE_DIGEST_PROXY }}
          IMAGE_DIGEST_LOG_FORWARDER: ${{ env.IMAGE_DIGEST_LOG_FORWARDER }}

      - name: Generate SBOM from payload (GitHub Action)
        uses: anchore/sbom-action@v0
        with:
          path: ${{ env.ARTIFACTS_PUBLISH }}/${{ steps.build_payload.outputs.payload_version }}/payload
          output-file: ${{ env.ARTIFACTS_PUBLISH }}/${{ steps.build_payload.outputs.payload_version }}/payload/payload.sbom.json

      - name: Attest payload SBOM (GitHub attestation)
        if: ${{ env.CHANNEL != 'dev' }}
        id: attest_sbom
        uses: actions/attest-build-provenance@v1
        with:
          subject-path: ${{ env.ARTIFACTS_PUBLISH }}/${{ steps.build_payload.outputs.payload_version }}/payload/payload.sbom.json

      - name: Persist SBOM attestation bundle into payload
        if: ${{ env.CHANNEL != 'dev' }}
        run: |
          cp "${{ steps.attest_sbom.outputs.bundle-path }}" "${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload/payload.sbom.json.intoto.jsonl"

      - name: Verify payload directory exists
        run: |
          echo "Checking payload directory after SBOM generation..."
          echo "VERSION=$VERSION"
          PAYLOAD_PATH="${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload"
          echo "Expected path: $PAYLOAD_PATH"
          if [[ -d "$PAYLOAD_PATH" ]]; then
            echo "âœ“ Payload directory exists"
            ls -la "$PAYLOAD_PATH" | head -20
          else
            echo "âŒ Payload directory MISSING!"
            echo "Contents of ${{ env.ARTIFACTS_PUBLISH }}:"
            ls -la "${{ env.ARTIFACTS_PUBLISH }}" || true
            find "${{ env.ARTIFACTS_PUBLISH }}" -type d 2>/dev/null | head -20
            exit 1
          fi

      - name: Refresh payload checksums
        run: |
          pushd "${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload" >/dev/null
          find . -type f ! -name 'SHA256SUMS' -print0 | sort -z | xargs -0 sha256sum > SHA256SUMS
          PAYLOAD_HASH=$(sha256sum SHA256SUMS | awk '{print $1}')
          echo "$PAYLOAD_HASH  SHA256SUMS" > payload.sha256
          popd >/dev/null

      - name: Attest payload directory (GitHub attestation)
        if: ${{ env.CHANNEL != 'dev' }}
        uses: actions/attest-build-provenance@v1
        with:
          subject-path: |
            ${{ env.ARTIFACTS_PUBLISH }}/${{ env.VERSION }}/payload/**/*

      - name: Debug payload directory
        run: |
          echo "VERSION=$VERSION"
          echo "ARTIFACTS_PUBLISH=${{ env.ARTIFACTS_PUBLISH }}"
          echo "Expected payload dir: ${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload"
          echo ""
          echo "Contents of artifacts/publish:"
          ls -la "${{ env.ARTIFACTS_PUBLISH }}" || echo "  (directory doesn't exist)"
          echo ""
          echo "Contents of artifacts/publish/$VERSION:"
          ls -la "${{ env.ARTIFACTS_PUBLISH }}/${VERSION}" || echo "  (directory doesn't exist)"
          echo ""
          echo "Contents of artifacts/publish/$VERSION/payload:"
          ls -la "${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload" || echo "  (directory doesn't exist)"

      - name: Package payload and transport (final)
        run: |
          scripts/release/package-artifacts.sh \
            --version "$VERSION" \
            --out "${{ env.ARTIFACTS_PUBLISH }}" \
            --launcher-channel "$CHANNEL" \
            --payload-dir "${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload" \
            --profile-env "${{ env.ARTIFACTS_PUBLISH }}/profile.env"
        env:
          IMAGE_DIGEST: ${{ env.IMAGE_DIGEST }}
          IMAGE_DIGEST_COPILOT: ${{ env.IMAGE_DIGEST_COPILOT }}
          IMAGE_DIGEST_CODEX: ${{ env.IMAGE_DIGEST_CODEX }}
          IMAGE_DIGEST_CLAUDE: ${{ env.IMAGE_DIGEST_CLAUDE }}
          IMAGE_DIGEST_PROXY: ${{ env.IMAGE_DIGEST_PROXY }}
          IMAGE_DIGEST_LOG_FORWARDER: ${{ env.IMAGE_DIGEST_LOG_FORWARDER }}

      - name: Set payload paths
        id: payload_paths
        run: |
          echo "payload_targz=${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload.tar.gz" >> "$GITHUB_OUTPUT"
          echo "transport_targz=${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/containai-${VERSION}.tar.gz" >> "$GITHUB_OUTPUT"
          echo "sbom=${{ env.ARTIFACTS_PUBLISH }}/${VERSION}/payload/payload.sbom.json" >> "$GITHUB_OUTPUT"

      - name: Set up ORAS
        uses: oras-project/setup-oras@v1

      - name: Generate payload bundle (file-level attestation)
        id: payload_bundle
        uses: actions/attest-build-provenance@v1
        with:
          subject-path: ${{ steps.payload_paths.outputs.payload_targz }}
          push-to-registry: false

      - name: Ensure payload bundle exists
        run: test -f "${{ steps.payload_bundle.outputs.bundle-path }}"

      - name: Push payload artifact (registry)
        id: push
        run: |
          ref="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-payload:${VERSION}"
          oras push "$ref" \
            --artifact-type application/vnd.containai.payload.v1 \
            "${{ steps.payload_paths.outputs.payload_targz }}:application/vnd.containai.payload.layer.v1+gzip" \
            "${{ steps.payload_paths.outputs.sbom }}:application/vnd.cyclonedx+json" \
            "${{ steps.payload_bundle.outputs.bundle-path }}":application/vnd.in-toto+json
          digest=$(oras manifest fetch --descriptor "$ref" | jq -r '.digest // empty')
          if [[ -z "$digest" ]]; then
            echo "Failed to resolve payload digest from registry" >&2
            exit 1
          fi
          echo "digest=${digest#*@}" >> "$GITHUB_OUTPUT"
          echo "ref=$ref@${digest#*@}" >> "$GITHUB_OUTPUT"

      - name: Attest payload artifact
        uses: actions/attest-build-provenance@v1
        with:
          subject-name: ${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-payload
          subject-digest: ${{ steps.push.outputs.digest }}
          push-to-registry: true

      - name: Attest transport tarball (GitHub attestation)
        if: ${{ env.CHANNEL != 'dev' }}
        id: attest_transport
        uses: actions/attest-build-provenance@v1
        with:
          subject-path: ${{ steps.payload_paths.outputs.transport_targz }}

      - name: Save transport attestation bundle
        if: ${{ env.CHANNEL != 'dev' }}
        run: |
          cp "${{ steps.attest_transport.outputs.bundle-path }}" "${{ steps.payload_paths.outputs.transport_targz }}.intoto.jsonl"

      - name: Upload transport tar artifact
        uses: actions/upload-artifact@v4
        with:
          name: transport-tarball
          path: ${{ steps.payload_paths.outputs.transport_targz }}
          if-no-files-found: error

      - name: Upload transport attestation artifact
        if: ${{ env.CHANNEL != 'dev' }}
        uses: actions/upload-artifact@v4
        with:
          name: transport-tarball-attestation
          path: ${{ steps.payload_paths.outputs.transport_targz }}.intoto.jsonl
          if-no-files-found: error

  publish-installer:
    name: Publish installer artifact
    needs:
      - determine-context
      - publish-metadata
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write
      attestations: write
    outputs:
      ref: ${{ steps.push.outputs.ref }}
      digest: ${{ steps.push.outputs.digest }}
    env:
      VERSION: ${{ needs.determine-context.outputs.version }}
      CHANNEL: ${{ needs.determine-context.outputs.channel }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up ORAS
        uses: oras-project/setup-oras@v1

      - name: Prepare installer artifact
        run: |
          cp install.sh installer.sh
          gzip -c installer.sh > installer.sh.gz

      - name: Generate installer bundle (file-level attestation)
        id: installer_bundle
        uses: actions/attest-build-provenance@v1
        with:
          subject-path: installer.sh.gz
          push-to-registry: false

      - name: Ensure installer bundle exists
        run: test -f "${{ steps.installer_bundle.outputs.bundle-path }}"

      - name: Push installer artifact
        id: push
        run: |
          ref="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-installer:${VERSION}"
          oras push "$ref" \
            --artifact-type application/vnd.containai.installer.v1 \
            installer.sh.gz:application/vnd.containai.installer.v1+sh \
            "${{ steps.installer_bundle.outputs.bundle-path }}":application/vnd.in-toto+json
          digest=$(oras manifest fetch --descriptor "$ref" | jq -r '.digest // empty')
          if [[ -z "$digest" ]]; then
            echo "Failed to resolve installer digest from registry" >&2
            exit 1
          fi
          echo "digest=${digest#*@}" >> "$GITHUB_OUTPUT"
          echo "ref=$ref" >> "$GITHUB_OUTPUT"

      - name: Tag installer with channel
        if: ${{ env.CHANNEL != 'dev' }}
        run: |
          oras tag "${{ steps.push.outputs.ref }}" "${{ env.CHANNEL }}"
          if [[ "${{ env.CHANNEL }}" == "prod" ]]; then
            oras tag "${{ steps.push.outputs.ref }}" "latest"
          fi

      - name: Attest installer artifact
        uses: actions/attest-build-provenance@v1
        with:
          subject-name: ${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-installer
          subject-digest: ${{ steps.push.outputs.digest }}
          push-to-registry: true

  cleanup-partial:
    name: Cleanup partial publishes
    needs:
      - determine-context
      - publish-payload
      - publish-metadata
      - publish-installer
    if: ${{ always() && needs.determine-context.outputs.push == 'true' && (needs.publish-installer.result != 'success' || needs.publish-metadata.result != 'success' || needs.publish-payload.result != 'success') }}
    runs-on: ubuntu-latest
    permissions:
      packages: write
    env:
      CHANNEL: ${{ needs.determine-context.outputs.channel }}
    steps:
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up ORAS
        uses: oras-project/setup-oras@v1

      - name: Cleanup payload artifact
        if: ${{ needs.publish-payload.outputs.payload_ref != '' }}
        run: |
          echo "Cleaning payload at ${{ needs.publish-payload.outputs.payload_ref }}"
          oras manifest delete "${{ needs.publish-payload.outputs.payload_ref }}" || true

      - name: Cleanup metadata artifact
        run: |
          ref_base="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-metadata"
          echo "Cleaning metadata tags"
          oras manifest delete "${ref_base}:${CHANNEL}" || true
          oras manifest delete "${ref_base}:channels" || true

      - name: Cleanup installer artifact
        if: ${{ needs.publish-installer.outputs.ref != '' }}
        run: |
          echo "Cleaning installer at ${{ needs.publish-installer.outputs.ref }}"
          oras manifest delete "${{ needs.publish-installer.outputs.ref }}" || true

  publish-metadata:
    name: Publish channel metadata
    needs:
      - determine-context
      - finalize-tags
      - publish-payload
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    env:
      CHANNEL: ${{ needs.determine-context.outputs.channel }}
      VERSION: ${{ needs.determine-context.outputs.version }}
      IMMUTABLE_TAG: ${{ needs.determine-context.outputs.immutable_tag }}
      MOVING_TAGS: ${{ needs.determine-context.outputs.moving_tags }}
      PAYLOAD_DIGEST: ${{ needs.publish-payload.outputs.payload_digest }}
      PAYLOAD_REF: ${{ needs.publish-payload.outputs.payload_ref }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up ORAS
        uses: oras-project/setup-oras@v1

      - name: Prepare metadata
        id: metadata
        run: |
          scripts/ci/write-channels-json.sh \
            --channel "$CHANNEL" \
            --version "$VERSION" \
            --immutable "$IMMUTABLE_TAG" \
            --moving-tags "${{ needs.determine-context.outputs.moving_tags }}" \
            --images-json '${{ needs.finalize-tags.outputs.images }}' \
            --payload-ref "$PAYLOAD_REF" \
            --payload-digest "$PAYLOAD_DIGEST" \
            --out channels.json
          cat channels.json

      - name: Push metadata artifact
        run: |
          ref_base="${{ env.REGISTRY }}/${{ env.IMAGE_NAMESPACE }}/containai-metadata"
          oras push "${ref_base}:${CHANNEL}" \
            --artifact-type application/vnd.containai.metadata.v1+json \
            channels.json:application/json
          # Keep a canonical tag for channel resolution
          oras push "${ref_base}:channels" \
            --artifact-type application/vnd.containai.metadata.v1+json \
            channels.json:application/json

  cleanup-ghcr:
    name: Retention and visibility
    needs:
      - determine-context
      - finalize-tags
      - publish-payload
      - publish-metadata
    if: ${{ needs.determine-context.outputs.push == 'true' }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Ensure packages are public
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OWNER: ${{ github.repository_owner }}
        run: |
          packages=(containai-base containai containai-copilot containai-codex containai-claude containai-proxy containai-log-forwarder containai-payload containai-metadata)
          for pkg in "${packages[@]}"; do
            if ! gh api --method PATCH "/orgs/${OWNER}/packages/container/${pkg}/settings" -f visibility=public 2>/dev/null; then
              gh api --method PATCH "/user/packages/container/${pkg}/settings" -f visibility=public 2>/dev/null || true
            fi
          done

      - name: Cleanup container versions with prod retention
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OWNER: ${{ github.repository_owner }}
        run: |
          set -euo pipefail
          cutoff_ts=$(date -u -d '180 days ago' +%s)
          declare -A min_keep=(
            [containai]=15
            [containai-base]=10
            [containai-copilot]=10
            [containai-codex]=10
            [containai-claude]=10
            [containai-proxy]=10
            [containai-log-forwarder]=10
            [containai-payload]=10
            [containai-metadata]=10
          )

          fetch_versions() {
            local pkg="$1"
            local res
            if res=$(gh api -H "Accept: application/vnd.github+json" \
              "/orgs/${OWNER}/packages/container/${pkg}/versions?per_page=100" 2>/dev/null); then
              echo "$res"
            else
              gh api -H "Accept: application/vnd.github+json" \
                "/user/packages/container/${pkg}/versions?per_page=100"
            fi
          }

          for pkg in "${!min_keep[@]}"; do
            echo "Processing $pkg..."
            json=$(fetch_versions "$pkg") || { echo "Failed to list versions for $pkg" >&2; continue; }
            count=$(jq 'length' <<<"$json")
            if [[ "$count" -eq 0 ]]; then
              echo "No versions for $pkg"; continue
            fi

            prod_entries=$(jq -r '[.[] | {id:.id, updated:(.updated_at|fromdate), tags:(.metadata.container.tags // [])}]' <<<"$json")
            latest_prod_id=$(jq -r 'map(select(.tags|index("prod"))) | max_by(.updated) | .id // empty' <<<"$prod_entries")
            keep_ids=()

            # Keep anything updated within the last 6 months
            while IFS= read -r id; do keep_ids+=("$id"); done < <(
              jq -r --argjson cutoff "$cutoff_ts" '.[] | select(.updated >= $cutoff) | .id' <<<"$prod_entries")

            # Keep prod-tagged within 6 months or latest prod regardless of age
            while IFS= read -r id; do keep_ids+=("$id"); done < <(
              jq -r --argjson cutoff "$cutoff_ts" --arg latest "$latest_prod_id" '
                .[] | select((.tags|index("prod")) and ((.updated >= $cutoff) or (.id == ($latest|tonumber)))) | .id'
              <<<"$prod_entries")

            # Non-prod retention: keep newest N
            keep_nonprod=$(jq -r --argjson n "${min_keep[$pkg]}" '
              [.[] | select(.tags|index("prod")|not) | {id, updated}] | sort_by(.updated) | reverse | .[:$n] | .[].id'
              <<<"$prod_entries")
            while IFS= read -r id; do [[ -n "$id" ]] && keep_ids+=("$id"); done <<<"$keep_nonprod"

            # Deduplicate keep_ids
            declare -A keep_map=()
            for id in "${keep_ids[@]}"; do keep_map[$id]=1; done

            delete_ids=()
            while IFS= read -r id; do
              [[ -z "$id" ]] && continue
              if [[ -z "${keep_map[$id]:-}" ]]; then
                delete_ids+=("$id")
              fi
            done < <(jq -r '.[].id' <<<"$prod_entries")

            for id in "${delete_ids[@]}"; do
              echo "Deleting $pkg version $id"
              gh api --method DELETE \
                "/orgs/${OWNER}/packages/container/${pkg}/versions/${id}" 2>/dev/null \
                || gh api --method DELETE \
                  "/user/packages/container/${pkg}/versions/${id}" 2>/dev/null \
                || echo "âš ï¸  Failed to delete $pkg version $id" >&2
            done
          done
